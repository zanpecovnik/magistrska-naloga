{"cells":[{"cell_type":"markdown","metadata":{"id":"RQ9KZBd3QKtJ"},"source":["**Check the GPU**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0Rh9ZpEQKNn"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"TcAnmvQ460eJ"},"source":["**Select model and target language**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fu7sl4N163YR"},"outputs":[],"source":["MODEL_TYPE = \"google/long-t5-tglobal-base\"\n","TARGET_LANG = \"eng\"\n","MAX_TOKEN_LEN = 4096\n","BATCH_SIZE = 4\n","SIZE_OF_TRAINING_SET = 0.2 # 1.0 === 100%"]},{"cell_type":"markdown","metadata":{"id":"zcrLbIVT7D_a"},"source":["**Install BLEURT**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4o5pSUu7HJn"},"outputs":[],"source":["!git clone https://github.com/google-research/bleurt.git\n","!pip install -q ./bleurt\n","\n","# !wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip .\n","# !unzip BLEURT-20.zip -d \"/content/drive/MyDrive/Colab Notebooks/magistrska/models/bleurt-checkpoints\"\n","\n","# !rm BLEURT-20.zip"]},{"cell_type":"markdown","metadata":{"id":"oBiMDQyR-4ex"},"source":["**Install packages from pip**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00sZQOuI-rsH"},"outputs":[],"source":["!pip install -q transformers\n","!pip install -qU pytorch-lightning\n","!pip install -q peft\n","!pip install -q torch\n","!pip install -q pandas\n","!pip install -q numpy\n","!pip install -q scikit-learn\n","!pip install -q rouge-score\n","!pip install -q spacy ftfy==4.4.3"]},{"cell_type":"markdown","metadata":{"id":"PPeg0xD_-_EO"},"source":["**Import libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zucSekWR-8iQ"},"outputs":[],"source":["import os\n","import json\n","import torch\n","import transformers\n","\n","import numpy as np\n","import pandas as pd\n","import pytorch_lightning as pl\n","\n","from bleurt import score\n","from rouge_score import rouge_scorer\n","\n","from os.path import exists\n","from torch.optim import AdamW\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from peft import get_peft_model, LoraConfig, TaskType\n","from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar, EarlyStopping\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from transformers import AutoTokenizer, LongT5ForConditionalGeneration"]},{"cell_type":"markdown","metadata":{"id":"2T4Tdao0w-6F"},"source":["\n","**Set random seed**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYaBNkhTxCfT"},"outputs":[],"source":["pl.seed_everything(42)"]},{"cell_type":"markdown","metadata":{"id":"-V8LWdZBBfvF"},"source":["**Load data to DataFrame**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_myVk2gBiXt"},"outputs":[],"source":["DIR_PATH = \"/content/drive/MyDrive/Colab Notebooks/magistrska/data\"\n","\n","def load_df_from_drive():\n","  return pd.read_csv(f\"{DIR_PATH}/dataframe-kas.csv\", encoding=\"utf-8\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0eRZJvQEECwl"},"outputs":[],"source":["print(\"Loading data from drive...\")\n","df = load_df_from_drive()\n","print(\"Finished.\")"]},{"cell_type":"markdown","metadata":{"id":"LV4lwG69gMKx"},"source":["**Remove any values that are null (there should be none) and reset index**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqKvncFgcdQ5"},"outputs":[],"source":["df = df.dropna()\n","df = df.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"XHJbuU1fge3-"},"source":["**Split into train, test and validation dataset (80 : 10 : 10)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8VuCJ9ggJW7"},"outputs":[],"source":["train_df, test_and_validation_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)\n","test_df, validation_df = train_test_split(test_and_validation_df, test_size=0.5, shuffle=True, random_state=42)\n","train_df.shape, test_df.shape, validation_df.shape\n","\n","del df"]},{"cell_type":"markdown","metadata":{"id":"Uwa9Ohla1T93"},"source":["**Create class for dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8dE04SFhSkG"},"outputs":[],"source":["class SummaryDataset(Dataset):\n","  def __init__(\n","      self,\n","      data: pd.DataFrame,\n","      tokenizer,\n","      text_max_token_len: int = MAX_TOKEN_LEN,\n","      summary_max_token_len: int = 256\n","  ):\n","    self.tokenizer = tokenizer\n","    self.data = data\n","    self.text_max_token_len = text_max_token_len\n","    self.summary_max_token_len = summary_max_token_len\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, index: int):\n","    data_row = self.data.iloc[index]\n","\n","    text_encoding = self.tokenizer(\n","        data_row[\"text\"],\n","        max_length=self.text_max_token_len,\n","        padding=\"max_length\",\n","        truncation=True,\n","        return_attention_mask=True,\n","        add_special_tokens=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    summary_eng_encoding = self.tokenizer(\n","        data_row[\"abstract_eng\"],\n","        max_length=self.summary_max_token_len,\n","        padding=\"max_length\",\n","        truncation=True,\n","        return_attention_mask=True,\n","        add_special_tokens=True,\n","        return_tensors=\"pt\"\n","    )\n","\n","    eng_labels = summary_eng_encoding[\"input_ids\"]\n","    eng_labels[eng_labels == 0] = -100\n","\n","    return {\n","        \"text\": data_row[\"text\"],\n","        \"text_input_ids\": text_encoding[\"input_ids\"].flatten(),\n","        \"text_attention_mask\": text_encoding[\"attention_mask\"].flatten(),\n","        \"summary_eng\": data_row[\"abstract_eng\"],\n","        \"summary_eng_labels\": eng_labels.flatten(),\n","        \"summary_eng_attention_mask\": summary_eng_encoding[\"attention_mask\"].flatten()\n","    }"]},{"cell_type":"markdown","metadata":{"id":"YqD34Sdk1XIB"},"source":["**Create summary data module**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUTdKDZd1STz"},"outputs":[],"source":["class SummaryDataModule(pl.LightningDataModule):\n","  def __init__(\n","      self,\n","      train_df: pd.DataFrame,\n","      test_df: pd.DataFrame,\n","      validation_df: pd.DataFrame,\n","      tokenizer,\n","      batch_size: int = 8,\n","      text_max_token_len: int = MAX_TOKEN_LEN,\n","      summary_max_token_len: int = 256\n","  ):\n","    super().__init__()\n","\n","    self.train_df = train_df\n","    self.test_df = test_df\n","    self.validation_df = validation_df\n","\n","    self.tokenizer = tokenizer\n","    self.batch_size = batch_size\n","    self.text_max_token_len = text_max_token_len\n","    self.summary_max_token_len = summary_max_token_len\n","\n","  def setup(self, stage=None):\n","    self.train_dataset = SummaryDataset(\n","        self.train_df,\n","        self.tokenizer,\n","        self.text_max_token_len,\n","        self.summary_max_token_len\n","    )\n","\n","    self.test_dataset = SummaryDataset(\n","        self.test_df,\n","        self.tokenizer,\n","        self.text_max_token_len,\n","        self.summary_max_token_len\n","    )\n","\n","    self.validation_dataset = SummaryDataset(\n","        self.validation_df,\n","        self.tokenizer,\n","        self.text_max_token_len,\n","        self.summary_max_token_len\n","    )\n","\n","  def train_dataloader(self):\n","    return DataLoader(\n","        self.train_dataset,\n","        batch_size=self.batch_size,\n","        shuffle=False,\n","        pin_memory=True,\n","        prefetch_factor=2,\n","        persistent_workers=True,\n","        num_workers=11\n","    )\n","\n","  def test_dataloader(self):\n","    return DataLoader(\n","        self.test_dataset,\n","        batch_size=self.batch_size,\n","        shuffle=False,\n","        pin_memory=True,\n","        prefetch_factor=2,\n","        persistent_workers=True,\n","        num_workers=11\n","    )\n","\n","  def val_dataloader(self):\n","    return DataLoader(\n","        self.validation_dataset,\n","        batch_size=self.batch_size,\n","        shuffle=False,\n","        pin_memory=True,\n","        prefetch_factor=2,\n","        persistent_workers=True,\n","        num_workers=11\n","    )"]},{"cell_type":"markdown","metadata":{"id":"q5--pggs6dBB"},"source":["**Create model class**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsI_xhTu6gpP"},"outputs":[],"source":["class SummaryModel(pl.LightningModule):\n","  def __init__(self, model_type, target_lang):\n","    super().__init__()\n","    self.target_lang = target_lang\n","    self.model_type = model_type\n","    self.init_tokenizer(model_type)\n","    self.init_model(model_type)\n","    self.rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n","    self.bleurt = score.BleurtScorer(\"drive/MyDrive/Colab Notebooks/magistrska/models/bleurt-checkpoints/BLEURT-20\")\n","    self.validation_step_outputs = {\"generated\": [], \"ground_truths\": []}\n","    self.validation_step_losses = []\n","    self.validation_scores = {\"loss\": []}\n","    self.test_step_outputs = {\"generated\": [], \"ground_truths\": []}\n","    self.test_scores = {\"bleurt\": [], \"rougeL_fmeasure\": [], \"rougeL_precision\": [], \"rougeL_recall\": []}\n","    self.save_hyperparameters()\n","\n","\n","  def init_tokenizer(self, model_type):\n","    self.tokenizer = AutoTokenizer.from_pretrained(model_type)\n","\n","\n","  def init_model(self, model_type):\n","    mod = LongT5ForConditionalGeneration.from_pretrained(model_type, return_dict=True)\n","\n","    # for name, module in mod.named_modules():\n","    #   print(name)\n","\n","    lora_config = LoraConfig(\n","        task_type=TaskType.SEQ_2_SEQ_LM,  # Type of task (sequence-to-sequence language modeling)\n","        r=4,  # Rank of the low-rank matrices\n","        lora_alpha=16,  # LoRA alpha\n","        target_modules=[\n","            \"q\", \"v\"\n","        ],  # Layers to apply LoRA (e.g., query and value projection)\n","        lora_dropout=0.1,  # Dropout rate for LoRA\n","    )\n","    self.model = get_peft_model(mod, lora_config)\n","\n","\n","  def generate_summaries(self, batch):\n","    input_ids = batch[\"text_input_ids\"]\n","    attention_mask = batch[\"text_attention_mask\"]\n","\n","    generated_ids = self.model.generate(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask,\n","      max_length=256, # usually abstracts do not exceed 250 words\n","      num_beams=2,\n","      repetition_penalty=2.5,\n","      length_penalty=1.0,\n","      early_stopping=True\n","    )\n","\n","    predictions = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","\n","    return predictions\n","\n","\n","  def average_of_list(self, lst):\n","    return sum(lst) / len(lst)\n","\n","\n","  def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n","    output = self.model(\n","      input_ids,\n","      attention_mask=attention_mask,\n","      labels=labels,\n","      decoder_attention_mask=decoder_attention_mask\n","    )\n","\n","    return output.loss, output.logits\n","\n","\n","  def training_step(self, batch, batch_index):\n","    loss, outputs = self._common_step(batch, batch_index)\n","\n","\n","    self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, logger=True, batch_size=BATCH_SIZE)\n","    return loss\n","\n","\n","  def validation_step(self, batch, batch_index):\n","    loss, outputs = self._common_step(batch, batch_index)\n","\n","    self.validation_step_losses.append(loss)\n","\n","    self.log(\"validation_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, logger=True, batch_size=BATCH_SIZE)\n","    return loss\n","\n","\n","  def on_validation_epoch_end(self):\n","    self.validation_scores[\"loss\"].append(self.average_of_list(self.validation_step_losses))\n","    self.validation_step_losses = []\n","\n","  def test_step(self, batch, batch_index):\n","    loss, outputs = self._common_step(batch, batch_index)\n","\n","    generated_predictions = self.generate_summaries(batch)\n","\n","    self.test_step_outputs[\"generated\"].extend(generated_predictions)\n","    self.test_step_outputs[\"ground_truths\"].extend(batch[f\"summary_{self.target_lang}\"])\n","\n","    self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, logger=True, batch_size=BATCH_SIZE)\n","    return loss\n","\n","\n","  def on_test_epoch_end(self):\n","    generated = self.test_step_outputs[\"generated\"]\n","    ground_truths = self.test_step_outputs[\"ground_truths\"]\n","\n","    bleurt_scores = self.bleurt.score(\n","        references=ground_truths,\n","        candidates=generated\n","      )\n","    avg_bleurt_score = self.average_of_list(bleurt_scores)\n","\n","    rouge_scores_fmeasure = []\n","    rouge_scores_precision = []\n","    rouge_scores_recall = []\n","    for i in range(len(generated)):\n","      rouge_score = self.rouge.score(generated[i], ground_truths[i])[\"rougeL\"]\n","      rouge_scores_fmeasure.append(rouge_score.fmeasure)\n","      rouge_scores_precision.append(rouge_score.precision)\n","      rouge_scores_recall.append(rouge_score.recall)\n","\n","    avg_rouge_score_fmeasure = self.average_of_list(rouge_scores_fmeasure)\n","    avg_rouge_score_precision = self.average_of_list(rouge_scores_precision)\n","    avg_rouge_score_recall = self.average_of_list(rouge_scores_recall)\n","\n","    self.test_scores[\"bleurt\"] = bleurt_scores\n","    self.test_scores[\"rougeL_fmeasure\"] = rouge_scores_fmeasure\n","    self.test_scores[\"rougeL_precision\"] = rouge_scores_precision\n","    self.test_scores[\"rougeL_recall\"] = rouge_scores_recall\n","\n","    self.log(\"test_bleurt\", avg_bleurt_score, prog_bar=True, on_step=False, on_epoch=True, logger=True, batch_size=BATCH_SIZE)\n","    self.log(\"test_rougeL_fmeasure\", avg_rouge_score_fmeasure, prog_bar=True, on_step=False, on_epoch=True, logger=True, batch_size=BATCH_SIZE)\n","    self.log(\"test_rougeL_precision\", avg_rouge_score_precision, prog_bar=True, on_step=False, on_epoch=True, logger=True, batch_size=BATCH_SIZE)\n","    self.log(\"test_rougeL_recall\", avg_rouge_score_recall, prog_bar=True, on_step=False, on_epoch=True, logger=True, batch_size=BATCH_SIZE)\n","\n","\n","  def _common_step(self, batch, batch_index):\n","    input_ids = batch[\"text_input_ids\"]\n","    attention_mask = batch[\"text_attention_mask\"]\n","    labels = batch[f\"summary_{self.target_lang}_labels\"]\n","    labels_attention_mask = batch[f\"summary_{self.target_lang}_attention_mask\"]\n","\n","    loss, outputs = self.forward(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        decoder_attention_mask=labels_attention_mask,\n","        labels=labels\n","    )\n","\n","    return loss, outputs\n","\n","\n","  def configure_optimizers(self):\n","    return AdamW(self.parameters(), lr=5e-5)\n"]},{"cell_type":"markdown","metadata":{"id":"Gwmr5c5E4WdS"},"source":["**Init tokenizer, model and data module**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UHbptlS5vxM"},"outputs":[],"source":["summary_model = SummaryModel(MODEL_TYPE, TARGET_LANG)\n","data_module = SummaryDataModule(train_df, test_df, validation_df, summary_model.tokenizer, batch_size=BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"s9QM-k0KvYVw"},"source":["**Make sure that the path to where the model will be saved exists in drive**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mvnwn46pvcPy"},"outputs":[],"source":["MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/magistrska/models\"\n","RESULTS_PATH = \"/content/drive/MyDrive/Colab Notebooks/magistrska/results\"\n","\n","if not os.path.exists(f\"{MODEL_PATH}/{summary_model.model_type}\"):\n","    os.mkdir(f\"{MODEL_PATH}/{summary_model.model_type}\")\n","\n","if not os.path.exists(f\"{MODEL_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}\"):\n","  os.mkdir(f\"{MODEL_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}\")\n","\n","if not os.path.exists(f\"{MODEL_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}/percentage_{SIZE_OF_TRAINING_SET * 100}\"):\n","  os.mkdir(f\"{MODEL_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}/percentage_{SIZE_OF_TRAINING_SET * 100}\")\n","\n","if not os.path.exists(f\"{RESULTS_PATH}/{summary_model.model_type}\"):\n","  os.mkdir(f\"{RESULTS_PATH}/{summary_model.model_type}\")\n","\n","if not os.path.exists(f\"{RESULTS_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}\"):\n","  os.mkdir(f\"{RESULTS_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}\")\n","\n","if not os.path.exists(f\"{RESULTS_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}/percentage_{SIZE_OF_TRAINING_SET * 100}\"):\n","  os.mkdir(f\"{RESULTS_PATH}/{summary_model.model_type}/to_{summary_model.target_lang}/percentage_{SIZE_OF_TRAINING_SET * 100}\")"]},{"cell_type":"markdown","metadata":{"id":"viGY6w4z8_Ik"},"source":["**Init trainer and save best model which has the lowest validation loss**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2FdXdVR8oNT"},"outputs":[],"source":["# stop training if validation loss is 3 times higher or equal to best validation loss\n","early_stop_callback = EarlyStopping(monitor=\"validation_loss\", min_delta=0.00, patience=3, verbose=False, mode=\"min\")\n","\n","checkpoint_callback = ModelCheckpoint(\n","    dirpath=f\"/content/drive/MyDrive/Colab Notebooks/magistrska/models/{summary_model.model_type}/to_{summary_model.target_lang}/percentage_{SIZE_OF_TRAINING_SET * 100}\",\n","    filename='{epoch}-{validation_loss:.5f}',\n","    save_top_k=1,\n","    verbose=True,\n","    monitor=\"validation_loss\",\n","    mode=\"min\"\n",")\n","\n","logger = TensorBoardLogger(\"lightning_logs\", name=f\"summary/{MODEL_TYPE}\")\n","\n","trainer = pl.Trainer(\n","    logger=logger,\n","    callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=10), early_stop_callback],\n","    accelerator=\"gpu\",\n","    devices=1,\n","    limit_train_batches=SIZE_OF_TRAINING_SET,\n","    precision=\"bf16-mixed\",\n","    gradient_clip_val=1.0,\n","    accumulate_grad_batches=16,\n","    num_sanity_val_steps=-1, # runs validation before training\n","    # max_epochs=1,\n","    check_val_every_n_epoch=1\n",")\n","\n","torch.set_float32_matmul_precision(\"medium\")"]},{"cell_type":"markdown","metadata":{"id":"TsmZSC3lPCYo"},"source":["**If needed, reload the best previous model and continue training**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1Vpn8YLPJxn"},"outputs":[],"source":["# BEST_MODEL_PATH = f\"/{MODEL_PATH}/{MODEL_TYPE}/to_{TARGET_LANG}/percentage_{SIZE_OF_TRAINING_SET * 100}\"\n","\n","# summary_model = SummaryModel.load_from_checkpoint(f\"{BEST_MODEL_PATH}/epoch=18-validation_loss=2.93664.ckpt\")"]},{"cell_type":"markdown","metadata":{"id":"9Y0shl8jB_V9"},"source":["**Train the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P__xUign91JN"},"outputs":[],"source":["trainer.fit(summary_model, datamodule=data_module)"]},{"cell_type":"markdown","metadata":{"id":"Z21twSkQfMxP"},"source":["**Load best model from trainer (or drive)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ciWVn8NfRod"},"outputs":[],"source":["# looks like: /content/drive/MyDrive/Colab Notebooks/magistrska/models/t5-small/to_eng/percentage_20.0/epoch=0-validation_loss=2.63198-validation_bleurt=0.35159-validation_rougeL_fmeasure=0.18982.ckpt\n","BEST_MODEL_PATH = trainer.checkpoint_callback.best_model_path\n","# BEST_MODEL_PATH = f\"/{MODEL_PATH}/{MODEL_TYPE}/to_{TARGET_LANG}/percentage_{SIZE_OF_TRAINING_SET * 100}/epoch=64-validation_loss=2.96666.ckpt\"\n","\n","if BEST_MODEL_PATH is None or BEST_MODEL_PATH == '':\n","  trained_model = summary_model\n","else:\n","  trained_model = SummaryModel.load_from_checkpoint(BEST_MODEL_PATH)"]},{"cell_type":"markdown","metadata":{"id":"MkDa_Q1wfYzK"},"source":["**Save results for validation during training epochs**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_N6zu8-dflkG"},"outputs":[],"source":["trained_model.validation_scores[\"loss\"] = [x.item() for x in trained_model.validation_scores[\"loss\"]]\n","df_with_logs = pd.DataFrame.from_dict(trained_model.validation_scores)\n","df_with_logs.to_csv(f\"{RESULTS_PATH}/{trained_model.model_type}/to_{trained_model.target_lang}/percentage_{SIZE_OF_TRAINING_SET * 100}/validation_results.csv\", encoding=\"utf-8\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"1CEgVKNN5du_"},"source":["**Test the model with the trainer**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gJnmTb2S5gpu"},"outputs":[],"source":["# Freeze parameters for testing\n","trained_model.freeze()\n","\n","trainer.test(trained_model, data_module)"]},{"cell_type":"markdown","metadata":{"id":"d4QNpNElEFVl"},"source":["**Save test DF to drive with results**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"w1Ruis_yDxBr"},"outputs":[],"source":["trainer_metrics = trainer.callback_metrics\n","trained_model_generated_test_outputs = trained_model.test_step_outputs[\"generated\"]\n","trained_model_test_scores = trained_model.test_scores\n","\n","data_module.test_df = data_module.test_df.drop(\"text\", axis=1)\n","\n","data_module.test_df[f\"generated_summary_{trained_model.target_lang}\"] = trained_model_generated_test_outputs\n","data_module.test_df[\"testing_bleurt_scores\"] = trained_model_test_scores[\"bleurt\"]\n","data_module.test_df[\"testing_rougeL_fmeasure_scores\"] = trained_model_test_scores[\"rougeL_fmeasure\"]\n","data_module.test_df[\"testing_rougeL_precision_scores\"] = trained_model_test_scores[\"rougeL_precision\"]\n","data_module.test_df[\"testing_rougeL_recall_scores\"] = trained_model_test_scores[\"rougeL_recall\"]\n","data_module.test_df[\"testing_average_bleurt_score\"] = [trainer_metrics[\"test_bleurt\"].item()] * len(trained_model_generated_test_outputs)\n","data_module.test_df[\"testing_average_rougeL_fmeasure_score\"] = [trainer_metrics[\"test_rougeL_fmeasure\"].item()] * len(trained_model_generated_test_outputs)\n","data_module.test_df[\"testing_average_rougeL_precision_score\"] = [trainer_metrics[\"test_rougeL_precision\"].item()] * len(trained_model_generated_test_outputs)\n","data_module.test_df[\"testing_average_rougeL_recall_score\"] = [trainer_metrics[\"test_rougeL_recall\"].item()] * len(trained_model_generated_test_outputs)\n","\n","testing_filename_csv = f\"{RESULTS_PATH}/{trained_model.model_type}/to_{trained_model.target_lang}/percentage_{SIZE_OF_TRAINING_SET * 100}/testing_results.csv\"\n","data_module.test_df.to_csv(testing_filename_csv, encoding=\"utf-8\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5HaqM33i1IKm"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"mount_file_id":"1c6y2deQC5UOrTb24aiTOmS1l7zecNoHd","authorship_tag":"ABX9TyMzKIbOp8IyTilVnia+6hzS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}